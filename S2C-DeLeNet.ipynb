{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import keras\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.activations import sigmoid, tanh\n",
    "import random\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "# Custom modules\n",
    "\n",
    "from metrics import *\n",
    "from baseline_classifier_models import *\n",
    "from baseline_segmentation_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dims= 256\n",
    "batch_= 8\n",
    "seed_ = 3+21+35+40+63\n",
    "class_type = 'categorical' #binary/categorical\n",
    "task_ = 'mask' # 'mask' : segementation, 'recon' : reconstruction\n",
    "\n",
    "train_segmentation_only = 0\n",
    "train_classification_only = 0\n",
    "train_combined = 1\n",
    "\n",
    "lr_ = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetClassifier(img_dims, class_type, type_=\"B4\", truncation=False) # B0-B7\n",
    "\n",
    "# model = DenseNetClassifier(img_dims, class_type, type_=\"121\", truncation=False) # 121, 169, 201\n",
    "# model = ResNetClassifier(img_dims, class_type, type_=\"50\") # 50, 101, 152\n",
    "# model = MobileNetClassifier(img_dims, class_type)\n",
    "# model = InceptionNetV3Classifier(img_dims, class_type, truncation=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Segmentation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(img_dims, 32) # parameter 16, 32\n",
    "# model = UNetPP(img_dims, 2) # parameter 1, 2\n",
    "# model = PSPNet(img_dims)\n",
    "# model = ResUNet(img_dims)\n",
    "# model= ResUnetPlusPlus(img_dims)\n",
    "# model = inceptionUnet(img_dims)\n",
    "# model = DCUNet(img_dims, img_dims, channels=3)\n",
    "# model = MSRF(img_dims)\n",
    "# model = swinUNet(img_dims)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2C-DeLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_names(model):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if layer._name == 'top_activation' or layer._name == 'relu' : \n",
    "            print(True)\n",
    "            layer._name = 'convm_b'\n",
    "        elif layer._name == 'pool4_conv' or layer._name == 'block6a_expand_activation' : \n",
    "            print(True)\n",
    "            layer._name = 'conv5_b'\n",
    "        elif layer._name == 'pool3_conv' or layer._name == 'block4a_expand_activation' : \n",
    "            print(True)\n",
    "            layer._name = 'conv4_b'\n",
    "        elif layer._name == 'pool2_conv' or layer._name == 'block3a_expand_activation' : \n",
    "            print(True)\n",
    "            layer._name = 'conv3_b'\n",
    "        elif layer._name == 'conv1/relu' or layer._name == 'block2a_expand_activation' : \n",
    "            print(True)\n",
    "            layer._name = 'conv2_b'\n",
    "\n",
    "\n",
    "def decoder_0(convm, conv5, conv4, conv3, conv2, conv1, start_neurons=16, task_='mask'):\n",
    "    if backbone_variant>0:\n",
    "        deconv5 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\", name='deconv5_c')(convm)\n",
    "        uconv5 = concatenate([deconv5, conv5])\n",
    "        uconv5 = Dropout(0.5)(uconv5)\n",
    "        uconv5 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", name='deconv5_b')(uconv5)\n",
    "        uconv5 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", name='deconv5_a')(uconv5) \n",
    "        convm_ = uconv5\n",
    "    else:\n",
    "        convm_=conv5\n",
    "    \n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\", name='deconv4_c')(convm_)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.5)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", name='deconv4_b')(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", name='deconv4_a')(uconv4)\n",
    "\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\", name='deconv3_c')(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.5)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", name='deconv3_b')(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", name='deconv3_a')(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\", name='deconv2_c')(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.5)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", name='deconv2_b')(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", name='deconv2_a')(uconv2)\n",
    "\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\", name='deconv1_c')(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.5)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", name='deconv1_b')(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", name='deconv1_a')(uconv1)\n",
    "    \n",
    "    if task_=='mask':\n",
    "        print('you chose to segment images')\n",
    "        output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\", name='final_mask')(uconv1)\n",
    "    elif task_=='recon':\n",
    "        print('you chose to reconstruct images')\n",
    "        output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "def build__model(summary_=False, task_='mask'):\n",
    "    if backbone_variant==-99:\n",
    "        print('YOU CHOSE UNET+MODIFIED DECODER 1')\n",
    "        input_layer = Input((img_dims, img_dims, 3))\n",
    "        # input_layer = tf.image.rgb_to_hsv(input_layer)\n",
    "        input_ = input_layer\n",
    "\n",
    "        conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", name='conv1_a')(input_layer)\n",
    "        conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", name='conv1_b')(conv1)\n",
    "        x1 = conv1\n",
    "        pool1 = MaxPooling2D((2, 2), name='pool1')(conv1)\n",
    "        pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "        conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", name='conv2_a')(pool1)\n",
    "        conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", name='conv2_b')(conv2)\n",
    "        x2 = conv2\n",
    "        pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "        pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "        conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", name='conv3_a')(pool2)\n",
    "        conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", name='conv3_b')(conv3)\n",
    "        x3 = conv3\n",
    "        pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "        pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "        conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", name='conv4_a')(pool3)\n",
    "        conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", name='conv4_b')(conv4)\n",
    "        x4 = conv4\n",
    "        pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "        pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "        # Middle\n",
    "        conv5 = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "        conv5 = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\", name='conv5_b')(conv5)\n",
    "        x5 = conv5\n",
    "        xm = None\n",
    "\n",
    "\n",
    "      # out = decoder_1(None, conv5, conv4, conv3, conv2, conv1, start_neurons=start_neurons)\n",
    "      # model = Model(input_layer, out)\n",
    "\n",
    "    elif np.abs(backbone_variant)==1:\n",
    "        model = tf.keras.applications.InceptionV3(False, input_shape=(img_dims, img_dims, 3) )\n",
    "        input_ = model.input\n",
    "        if backbone_variant<0:\n",
    "            x4 = GlobalAveragePooling2D()(model.layers[-83].output) \n",
    "\n",
    "\n",
    "    elif np.abs(backbone_variant)>=12 and np.abs(backbone_variant)<20:\n",
    "        print(\"You Chose EFFNET\")\n",
    "\n",
    "        if np.abs(backbone_variant)==12: model = tf.keras.applications.EfficientNetB2(False, input_shape=(img_dims, img_dims, 3)  )\n",
    "        elif np.abs(backbone_variant)==13: model = tf.keras.applications.EfficientNetB3(False, input_shape=(img_dims, img_dims, 3)  )\n",
    "        elif np.abs(backbone_variant)==14: model = tf.keras.applications.EfficientNetB4(False, input_shape=(img_dims, img_dims, 3)  )\n",
    "\n",
    "        input_ = model.input\n",
    "\n",
    "        if backbone_variant>0:\n",
    "            xm = model.get_layer('top_activation').output #'convm_b'\n",
    "        else:\n",
    "            xm= None\n",
    "        x5 = model.get_layer('block6a_expand_activation').output #'conv5_b'\n",
    "        x4 = model.get_layer('block4a_expand_activation').output #'conv4_b'\n",
    "        x3 = model.get_layer('block3a_expand_activation').output #'conv3_b'\n",
    "        x2 = model.get_layer('block2a_expand_activation').output #'conv2_b'\n",
    "        x1 = Conv2D(start_neurons , (3, 3), activation=\"relu\", padding=\"same\")(model.input)\n",
    "        x1 = Conv2D(start_neurons , (3, 3), activation=\"relu\", padding=\"same\", name='conv1_b')(x1)\n",
    "\n",
    "\n",
    "\n",
    "    elif np.abs(backbone_variant)>=21 and np.abs(backbone_variant)<30:\n",
    "        print(\"You Chose DENSENET\")\n",
    "        if np.abs(backbone_variant)==21: model = tf.keras.applications.DenseNet121(False, input_shape=(img_dims, img_dims, 3)  )\n",
    "        elif np.abs(backbone_variant)==22: model = tf.keras.applications.DenseNet169(False, input_shape=(img_dims, img_dims, 3)  )\n",
    "        elif np.abs(backbone_variant)==23: model = tf.keras.applications.DenseNet201(False, input_shape=(img_dims, img_dims, 3)  )\n",
    "\n",
    "        input_ = model.input\n",
    "\n",
    "        if backbone_variant>0:\n",
    "            xm = model.get_layer('relu').output #'convm_b'\n",
    "        else:\n",
    "            xm= None\n",
    "        x5 = model.get_layer('pool4_conv').output #'conv5_b'\n",
    "        x4 = model.get_layer('pool3_conv').output #'conv4_b'\n",
    "        x3 = model.get_layer('pool2_conv').output #'conv3_b'\n",
    "        x2 = model.get_layer('conv1/relu').output #'conv2_b'\n",
    "        x1 = Conv2D(start_neurons , (3, 3), activation=\"relu\", padding=\"same\")(model.input)\n",
    "        x1 = Conv2D(start_neurons , (3, 3), activation=\"relu\", padding=\"same\", name='conv1_b')(x1)\n",
    "\n",
    "\n",
    "    if decoder_variant==0:\n",
    "        out = decoder_0(xm, x5, x4, x3, x2, x1, start_neurons, task_=task_)\n",
    "    elif decoder_variant==1:\n",
    "        out = decoder_1(xm, x5, x4, x3, x2, x1, start_neurons)\n",
    "\n",
    "\n",
    "    model = Model(input_, out)\n",
    "\n",
    "  # print(x1.shape, x2.shape, x3.shape, x4.shape, x5.shape, xm)\n",
    "\n",
    "    layer_names(model)\n",
    "    \n",
    "    \n",
    "      \n",
    "    model.compile(loss= dice_coef_loss, #'binary_crossentropy'\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=lr_,\n",
    "                                                      beta_1=0.9,\n",
    "                                                      beta_2=0.999,\n",
    "                                                      epsilon=None,\n",
    "                                                      amsgrad=False),\n",
    "                metrics=['accuracy',precision, recall, dice_coef, iou, mcc, XOR_Error])\n",
    "\n",
    "    if summary_: \n",
    "        model.summary()\n",
    "    return model, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Custom Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_variant = 14\n",
    "                        #  type number mapping ...  \n",
    "                        #                            1: inception_untr,   -1:inception_tr\n",
    "                        #                           12: EffB2_untr,      -12: EffB2_tr ,     13: EffB3_untr,      -13: EffB3_tr,     14: EffB4_untr,      -14: EffB4_tr \n",
    "                        #                           21: dense121_untr,   -21: dense121_tr,   22: dense169_untr,   -22: dense169_tr,  23: dense201_untr,   -23: dense201_tr\n",
    "\n",
    "decoder_variant = 0     #  type number mapping ...  0: vanilla,           \n",
    "\n",
    "start_neurons = 16      #  decoder size: either 16 (light) or 32 (heavy)\n",
    "\n",
    "\n",
    "print('BV :', backbone_variant, '     DV :', decoder_variant, '    image level neurons :', start_neurons)\n",
    "print('  ')\n",
    "\n",
    "model,_ = build__model(True,'mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Combined Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Segmentation Model First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_sort = 2           \n",
    "\n",
    "backbone_variant = 14\n",
    "                        #  type number mapping ... \n",
    "                        #                            1: inception_untr,   -1:inception_tr\n",
    "                        #                           12: EffB2_untr,      -12: EffB2_tr ,     13: EffB3_untr,      -13: EffB3_tr,     14: EffB4_untr,      -14: EffB4_tr \n",
    "                        #                           21: dense121_untr,   -21: dense121_tr,   22: dense169_untr,   -22: dense169_tr,  23: dense201_untr,   -23: dense201_tr\n",
    "\n",
    "decoder_variant = 0     #  type number mapping ...  0: vanilla,            \n",
    "\n",
    "start_neurons = 16      #  decoder size: either 16 (light) or 32 (heavy)\n",
    "\n",
    "print('BV :', backbone_variant, '     DV :', decoder_variant, '    image level neurons :', start_neurons)\n",
    "print('  ')\n",
    "\n",
    "test_dict = {\"2\": build__model}\n",
    "\n",
    "model,T = test_dict[str(what_sort)](False,task_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Segmentor Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_weights = '../Weights/HAM_BV14_DV0_light.h5'\n",
    "\n",
    "# model.load_weights(set_weights)\n",
    "\n",
    "for L in model.layers[:]:\n",
    "    L.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Intermediate Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOI = ['conv1_', 'conv2_', 'conv3_', 'conv4_', 'conv5_', 'convm_']  #LOI:layer of interest :encoder\n",
    "LOI2 = ['deconv1_', 'deconv2_', 'deconv3_', 'deconv4_', 'deconv5_', 'convm_']  #LOI:layer of interest : decoder\n",
    "\n",
    "LOI_name = 'b' #'a''b'\n",
    "\n",
    "layer_outs = []\n",
    "for i in range(len(LOI)-(backbone_variant<0)*1):\n",
    "    if i+1==len(LOI)-(backbone_variant<0)*1:\n",
    "        LOI[i] = LOI[i]+'b'\n",
    "    else:\n",
    "        LOI[i] = LOI[i]+LOI_name\n",
    "    layer_outs.append(model.get_layer(LOI[i]).output)\n",
    "    print(layer_outs[-1])\n",
    "\n",
    "LOI = LOI2\n",
    "LOI_name = 'a'\n",
    "for i in range(len(LOI)-(backbone_variant<0)*1):\n",
    "    if i+1==len(LOI)-(backbone_variant<0)*1:\n",
    "        LOI[i] = LOI[i]+'b'\n",
    "    else:\n",
    "        LOI[i] = LOI[i]+LOI_name\n",
    "    layer_outs.append(model.get_layer(LOI[i]).output)\n",
    "    print(layer_outs[-1])\n",
    "\n",
    "class_segmodel = Model(model.input, [layer_outs[:]])\n",
    "len(layer_outs[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Final Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_classifier(neurons=16, MLP_parted=1, lighter_=False, classes_=7):   #classify 3 with both encoder and decoder\n",
    "    X0 = Input((img_dims, img_dims, 3))\n",
    "    lois = class_segmodel(X0)\n",
    "    lois1 = lois[0][:6]\n",
    "    lois2 = lois[0][-6:]\n",
    "    print(lois[0][6])\n",
    "    lighter_ = lighter_*1\n",
    "  \n",
    "    def feature_propagation(x, z, f):  \n",
    "        # FCM\n",
    "        x = Conv2D(f, 3, padding='same', activation=LeakyReLU(0.1))(x)  \n",
    "        x_ = Conv2D(f, 3, padding='same', activation=LeakyReLU(0.1))(x)\n",
    "        \n",
    "        p = DepthwiseConv2D(1, padding='same', activation=LeakyReLU(0.1))(z) \n",
    "        p_ = Conv2D(f, 3, padding='same', activation=LeakyReLU(0.1))(p)\n",
    "        \n",
    "        x = MaxPool2D((2,2))(x_)\n",
    "        p = MaxPool2D((2,2))(p_)      \n",
    "\n",
    "        # 3DLR\n",
    "        rx = UpSampling2D()(x)\n",
    "        rp = UpSampling2D()(p)\n",
    "\n",
    "        p = concatenate([x,p])\n",
    "\n",
    "        rx = DepthwiseConv2D(1, padding='same', activation=LeakyReLU(0.1))(rx) \n",
    "        rx = Conv2D(f, 3, padding='same', activation=LeakyReLU(0.1))(rx)\n",
    "\n",
    "        rp = DepthwiseConv2D(1, padding='same', activation=LeakyReLU(0.1))(rp) \n",
    "        rp = Conv2D(f, 3, padding='same', activation=LeakyReLU(0.1))(rp)\n",
    "        \n",
    "        rx = subtract([x_,rx])\n",
    "        rp = subtract([p_,rp])\n",
    "        r = concatenate([rx,rp])\n",
    "\n",
    "        p = Conv2D(2*f, 3, padding='same', activation=LeakyReLU(0.1))(p)\n",
    "        return p, r\n",
    "\n",
    "    for k in range(2):\n",
    "        if k==0:  \n",
    "          lois_ = lois1\n",
    "          X=X0\n",
    "        else:     \n",
    "          lois_ = lois2\n",
    "          X=X0\n",
    "\n",
    "        for i in range(len(lois_)):      \n",
    "          if i==len(lois_)-1:\n",
    "            _, tr = feature_propagation(X, lois_[i], neurons*2**(i-k*lighter_))\n",
    "          else:\n",
    "            tp, tr = feature_propagation(X, lois_[i], neurons*2**(i-k*lighter_))\n",
    "\n",
    "          X = tp\n",
    "\n",
    "        x = GlobalAveragePooling2D()(tp)\n",
    "        r = GlobalAveragePooling2D()(tr)  \n",
    "\n",
    "        x = Dense((2**(int(np.log2(x.shape[-1]))))//2, LeakyReLU(0.1))(x)\n",
    "        x = Dense(x.shape[-1]//4, LeakyReLU(0.1))(x)\n",
    "        r = Dense((2**(int(np.log2(r.shape[-1]))))//2, LeakyReLU(0.1))(r)\n",
    "        r = Dense(r.shape[-1]//4, LeakyReLU(0.1))(r)\n",
    "        x = concatenate([x,r])    \n",
    "        \n",
    "        if k==0:          \n",
    "          x1 = Dense(x.shape[-1], LeakyReLU(0.1))(x)\n",
    "        else:\n",
    "          x2 = Dense(x.shape[-1], LeakyReLU(0.1))(x)\n",
    "\n",
    "    x = concatenate([x1,x2])         \n",
    "        \n",
    "    if class_type=='binary':\n",
    "      x = Dense(1, 'sigmoid')(x)\n",
    "    else:\n",
    "      x = Dense(classes_, 'softmax')(x)\n",
    "    print(x)\n",
    "    \n",
    "    model = Model(X0, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = combined_classifier(lighter_=True,classes_=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../../SkinData/HAM10000/Split_class/Train' \n",
    "dir_val = '../../SkinData/HAM10000/Split_class/Test' \n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=15,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            # vertical_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "                            \n",
    "train_gen = datagen.flow_from_directory(directory=dir,\n",
    "                                        target_size=(img_dims, img_dims), \n",
    "                                        batch_size=batch_,\n",
    "                                        class_mode=class_type,\n",
    "                                        shuffle=True,)\n",
    "\n",
    "datagen_test=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_gen = datagen_test.flow_from_directory(directory=dir_val,\n",
    "                                    target_size=(img_dims, img_dims),\n",
    "                                    batch_size=1,\n",
    "                                    class_mode=class_type,\n",
    "                                    shuffle=True,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '../../SkinData/HAM10000/Split_seg/Train'\n",
    "source_path_val = '../../SkinData/HAM10000/Split_seg/Val'\n",
    "\n",
    "\n",
    "def adjust_data(img,mask):\n",
    "    # img = rgb_cancellation(img)#.........augmentations, if need be\n",
    "    img = img / 255.\n",
    "    mask = mask / 255.\n",
    "    if not task_=='recon':\n",
    "        mask[mask > 0.5] = 1.0\n",
    "        mask[mask <= 0.5] = 0.0    \n",
    "    return (img, mask)\n",
    "\n",
    "folders = ['Img','Mask']\n",
    "folders_val=['Img', 'Mask']\n",
    "\n",
    "def my_generator(batch_size_):\n",
    "    imggen = ImageDataGenerator(rotation_range=0.1,\n",
    "                            width_shift_range=0.05,\n",
    "                            height_shift_range=0.05,\n",
    "                            shear_range=0.05,\n",
    "                            zoom_range=0.05,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "    \n",
    "    data_generator = imggen.flow_from_directory(directory = source_path,\n",
    "                                                target_size = (img_dims,img_dims),\n",
    "                                                color_mode = 'rgb',\n",
    "                                                classes = [folders[0]],\n",
    "                                                class_mode = None,\n",
    "                                                batch_size = batch_size_,\n",
    "                                                seed = seed_,\n",
    "                                                shuffle = True)\n",
    "    \n",
    "    mask_generator = imggen.flow_from_directory(directory = source_path,\n",
    "                                                target_size = (img_dims,img_dims),\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 classes = [folders[1]],\n",
    "                                                class_mode = None,\n",
    "                                                batch_size = batch_size_,\n",
    "                                                seed = seed_,\n",
    "                                                shuffle = True)\n",
    "    \n",
    "    train_gen = zip(data_generator, mask_generator)\n",
    "    \n",
    "    for (img, mask) in train_gen:\n",
    "        img, mask = adjust_data(img, mask)\n",
    "        yield (img,mask)\n",
    "    \n",
    "\n",
    "def my_generator_val(batch_size_):\n",
    "\n",
    "    imggen = ImageDataGenerator()\n",
    "    \n",
    "    data_generator = imggen.flow_from_directory(directory = source_path_val,\n",
    "                                                            target_size = (img_dims,img_dims),\n",
    "                                                            color_mode = 'rgb',\n",
    "                                                            classes = [folders_val[0]],\n",
    "                                                            class_mode = None,\n",
    "                                                            batch_size = batch_size_,\n",
    "                                                            seed = seed_,\n",
    "                                                            shuffle = False)\n",
    "    mask_generator = imggen.flow_from_directory(directory = source_path_val,\n",
    "                                                target_size = (img_dims,img_dims),\n",
    "                                                color_mode = 'grayscale',\n",
    "                                                classes = [folders_val[1]],\n",
    "                                                class_mode = None,\n",
    "                                                batch_size = batch_size_,\n",
    "                                                seed = seed_,\n",
    "                                                shuffle = False)\n",
    "\n",
    "    train_gen = zip(data_generator, mask_generator)\n",
    "    \n",
    "    for (img, mask) in train_gen:\n",
    "        img, mask = adjust_data(img, mask)\n",
    "        yield (img,mask)\n",
    "\n",
    "print('Val Img, Label, Train Img, Label')  \n",
    "len(os.listdir(source_path_val+'/'+folders_val[1])), len(os.listdir(source_path_val+'/'+folders_val[0])), len(os.listdir(source_path+'/'+folders[1])), len(os.listdir(source_path+'/'+folders[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_destination = '../Logs'\n",
    "weight_destinattion = '../Weights'\n",
    "\n",
    "run_id = 'ashol_model_mama'   #do this with plot\n",
    "\n",
    "weight_file = weight_destinattion + '/' + run_id + '.h5'\n",
    "log_dir = log_destination + '/' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_segmentation_only==1:\n",
    "    model.compile(loss= dice_coef_loss, # 'categorical_crossentropy', #'binary_crossentropy' ..  .. weighted_binary_crossentropy .. weighted_binary_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=lr_),\n",
    "                metrics=['accuracy',precision, recall, dice_coef, iou, mcc, XOR_Error])\n",
    "\n",
    "    monitor_ = 'val_dice_coef'\n",
    "    mode_ = 'max'\n",
    "    \n",
    "else:\n",
    "    model.compile(loss= 'categorical_crossentropy', # 'categorical_crossentropy', #'binary_crossentropy' ..  .. weighted_binary_crossentropy .. weighted_binary_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=lr_),\n",
    "                metrics=['accuracy', precision, recall, mcc])\n",
    "\n",
    "    monitor_ = 'val_accuracy'\n",
    "    mode_ = 'max'\n",
    "\n",
    "    \n",
    "weight_saver = ModelCheckpoint(weight_file, \n",
    "                               monitor=monitor_,\n",
    "                               mode =mode_,\n",
    "                               save_best_only=True,\n",
    "                               save_weights_only=True,\n",
    "                               verbose=1)\n",
    "\n",
    "annealer = ReduceLROnPlateau(monitor='loss',\n",
    "                             factor=0.5,\n",
    "                             patience=5,\n",
    "                             min_lr=1e-8,\n",
    "                             verbose=1)\n",
    "\n",
    "hist_csv_file = weight_destinattion + '/' + run_id+'.csv'\n",
    "csv_logger = CSVLogger(hist_csv_file, append=True)\n",
    "\n",
    "factor = batch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_segmentation_only==1:\n",
    "      print('*******************ONLY SEGMENTATION*******************')\n",
    "      ##>>> *** For Segmentation\n",
    "      history= model.fit(my_generator(batch_),\n",
    "              steps_per_epoch = len(os.listdir(source_path+'/'+folders[1]))//(factor),\n",
    "              validation_data = my_generator_val(batch_), \n",
    "              validation_steps= len(os.listdir(source_path_val+'/'+folders_val[1]))//(batch_),                          \n",
    "              epochs=80,\n",
    "              verbose=1, \n",
    "              callbacks = [weight_saver , annealer, csv_logger]\n",
    "              )\n",
    "        \n",
    "elif train_classification_only==1:\n",
    "      ##>>> *** For Classification\n",
    "      print('*******************ONLY CLASSIFICATION*******************')\n",
    "      history= model.fit(train_gen,\n",
    "                            steps_per_epoch=8019//(batch_),\n",
    "                            epochs=100,\n",
    "                            verbose=1,\n",
    "                            validation_data=val_gen,\n",
    "                            validation_steps=998//batch_,\n",
    "                            callbacks=[weight_saver , annealer, csv_logger],\n",
    "                         )\n",
    "                         \n",
    "elif train_combined==1:\n",
    "    print('*******************BOTH CLASS+SEG*******************')\n",
    "    ## Combined Training\n",
    "    history= model.fit(train_gen,\n",
    "                        steps_per_epoch=8019//(factor),\n",
    "                        epochs=150,\n",
    "                        verbose=1,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=998, \n",
    "                        callbacks = [weight_saver , annealer, csv_logger], \n",
    "                     )\n",
    "\n",
    "else:\n",
    "    print(\"Specify which one you want to train\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (For Segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ = weight_file\n",
    "model.load_weights(weight_)\n",
    "\n",
    "source_path_val = '../../SkinData/HAM10000/Split_seg/Val' #'../../SkinData/HAM10000/Split_seg/Test'\n",
    "\n",
    "model.compile(metrics=['accuracy',precision, recall, dice_coef, iou, mcc, XOR_Error,\n",
    "                        tf.keras.metrics.AUC(num_thresholds=6, curve='ROC', from_logits=True,\n",
    "                        thresholds=[0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
    "                        )\n",
    "                        ])\n",
    "\n",
    "if train_segmentation_only:\n",
    "    evals= model.evaluate(my_generator_val(1), verbose=1, steps=len(os.listdir(source_path_val+'/'+folders_val[1])))\n",
    "\n",
    "print(weight_)\n",
    "# print('BV :', backbone_variant, '     DV :', decoder_variant, '    image level neurons :', start_neurons)\n",
    "print('  ')\n",
    "\n",
    "evals, source_path_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path_val = '../../SkinData/HAM10000/Split_seg/Val' #'../../SkinData/HAM10000/Split_seg/Test'\n",
    "gt_names = [] \n",
    "\n",
    "# weight_ = 'SkinData/Weights/DC-UNet.h5'\n",
    "weight_ = weight_file\n",
    "model.load_weights(weight_)\n",
    "\n",
    "print(source_path_val)\n",
    "print(weight_)\n",
    "\n",
    "how_many= 300\n",
    "\n",
    "X= np.zeros((how_many,img_dims,img_dims,3), dtype=float)\n",
    "Yh = np.zeros(((how_many, img_dims, img_dims, 1)), dtype=float)\n",
    "Y = np.zeros(((how_many, img_dims, img_dims)), dtype=float)\n",
    "\n",
    "instance= 0 %len(os.listdir(source_path_val+'/'+folders_val[1]))\n",
    "\n",
    "for i in range(how_many):\n",
    "  print(i)\n",
    "  rotate_im = 0\n",
    "  temp = cv2.imread(source_path_val+'/'+folders_val[0]+'/'+np.sort(os.listdir(source_path_val+'/'+folders_val[0]))[instance+i])\n",
    "\n",
    "\n",
    "  temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "  tempx = cv2.resize(temp, (img_dims,img_dims))\n",
    "  X[i] = np.rot90(tempx,rotate_im//90,)\n",
    "\n",
    "  def power_law(x , t, rgb=False):\n",
    "    x = x**t\n",
    "    if rgb: \n",
    "      x = (x*255).astype(int)  \n",
    "    return x\n",
    "\n",
    "  a = 0.5 #random.random()\n",
    "  contrast = a+0.5\n",
    "  # print('contrast:', contrast)\n",
    "\n",
    "  Yh[i] = model.predict(power_law(X[i:i+1]/255.0, contrast))\n",
    "\n",
    "  temp = cv2.imread(source_path_val+'/'+folders_val[1]+'/'+np.sort(os.listdir(source_path_val+'/'+folders_val[1]))[instance+i])\n",
    "  \n",
    "  gt_names.append(np.sort(os.listdir(source_path_val+'/'+folders_val[1]))[instance+i])\n",
    "  Y[i] = np.rot90(cv2.resize(temp, (img_dims,img_dims))[:,:,0], rotate_im//90,)\n",
    "  temp2 = (Y[i]>128)*1\n",
    "  temp2 = np.sum(temp2)/(temp2.shape[0]*temp2.shape[1])\n",
    "  # print(temp2*100, '% -->', (img_dims**2)*temp2)\n",
    "\n",
    "\n",
    "np.unique(Yh), np.mean(Yh), (np.max(Yh[0,:,:,0])+np.min(Yh[0,:,:,0]))*0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_code_pred(x,y):\n",
    "  y = np.expand_dims(y,-1)\n",
    "  x = np.expand_dims(x,-1)\n",
    "  y = np.concatenate((y,y,y),-1)\n",
    "  x[x>=20]=255\n",
    "  x[x<20]=0\n",
    "\n",
    "\n",
    "  def colourize(x,r,g,b):\n",
    "    x[:,:,0][x[:,:,0]>0.1]=r\n",
    "    x[:,:,1][x[:,:,1]>0.1]=g\n",
    "    x[:,:,2][x[:,:,2]>0.1]=b\n",
    "    return x.astype(int)\n",
    "\n",
    "  tp = (x/255)*y\n",
    "  fp = (1.0-(x/255))*y\n",
    "  fn = (x/255)*(1.0-y)\n",
    "\n",
    "  tp = colourize(tp,0,255,0) #green\n",
    "  fn = colourize(fn,255,0,0) #red\n",
    "  fp = colourize(fp,0,80,255) #blue\n",
    "\n",
    "  return x,y, fp+tp+fn\n",
    "\n",
    "d_ = 0\n",
    "p_ = 0\n",
    "r_ = 0\n",
    "j_ = 0\n",
    "f2_= 0\n",
    "c = 1e-8\n",
    "\n",
    "show_how= 300\n",
    "plot_it= True\n",
    "selections = [173, 164, 88, 299, 263, 215]\n",
    "the_dices = []\n",
    "the_dices_idx = []\n",
    "\n",
    "for i in range(how_many):\n",
    "  \n",
    "  Yh_ = 1.0*(Yh[i][:,:,0]>1/2)\n",
    "  A,B,C= colour_code_pred(Y[i]*1,Yh_)\n",
    "    \n",
    "  \n",
    "  Yh_thresh = 1.0*(Yh[i,:,:,0])\n",
    "\n",
    "  dice = np.array(dice_coef(Y[i,:,:]/255, Yh_thresh))\n",
    "  prec = np.array(precision(Y[i,:,:]/255, Yh_thresh))\n",
    "  dice_range = (dice>=0.60) and (dice<=0.998)\n",
    "\n",
    "  ALL = (i+1) in selections\n",
    "  # ALL = True\n",
    "\n",
    "    \n",
    "   \n",
    "  if ALL and (i<show_how and dice_range):\n",
    "    c+=1\n",
    "    d_ = d_+np.array(dice_coef(Y[i,:,:]/255, Yh_thresh))\n",
    "    p_ = p_+ np.array(precision(Y[i,:,:]/255, Yh_thresh))\n",
    "    r_ = r_+ np.array(recall(Y[i,:,:]/255, Yh_thresh))\n",
    "    j_ = j_+np.array(iou(Y[i,:,:]/255, Yh_thresh))\n",
    "    if plot_it:\n",
    "      plt.figure(figsize=(20,20))\n",
    "      plt.subplot(1,4,1), plt.imshow(power_law(X[i]/255, contrast , True))\n",
    "      plt.axis('off')\n",
    "      plt.title('Main Image')\n",
    "      plt.subplot(1,4,2), plt.imshow(Y[i],cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title('Ground Truth')\n",
    "      plt.subplot(1,4,3), plt.imshow(Yh[i][:,:,0],cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title('Segmented Lesion')\n",
    "      plt.subplot(1,4,4), plt.imshow(C,cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title('Regions of Interests')\n",
    "      plt.show()\n",
    "\n",
    "    print(i+1)\n",
    "    print(gt_names[i])\n",
    "    print('Current Image model___dice:', np.array(dice_coef(Y[i,:,:]/255, Yh_thresh)),\n",
    "           'precision:', np.array(precision(Y[i,:,:]/255, Yh_thresh)),\n",
    "           'recall:', np.array(recall(Y[i,:,:]/255, Yh_thresh)) ,\n",
    "           'iou:', np.array(iou(Y[i,:,:]/255, Yh_thresh)))\n",
    "    print('mse:' , np.mean(((Y[i,:,:]/255)-Yh_thresh)**2))\n",
    "    the_dices.append(np.array(dice_coef(Y[i,:,:]/255, Yh_thresh)))\n",
    "    the_dices_idx.append(i+1)\n",
    "    print(c, 'Cummulative model___precision:',p_/(c),' - recall:', r_/(c), '- dice: ', d_/(c),' - iou:', j_/(c))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (For Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = dir_val #validation/test data  \n",
    "weight_file = '../Weights/best.h5'\n",
    "model.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_val=\"/content/drive/MyDrive/Terms/Thesis/WCE DATA/Binary And Multiple Class/Validation/Val_Normal_Angiectasia\"\n",
    "\n",
    "files_list= np.sort(os.listdir(data_dir))\n",
    "# model.evaluate(val_gen)\n",
    "\n",
    "tot=0\n",
    "tot_classes = len(files_list)\n",
    "conf_array=np.zeros((tot_classes,tot_classes), dtype=int)\n",
    "\n",
    "for k in range(tot_classes):\n",
    "  main_path = data_dir+'/'+files_list[k]  \n",
    "  for i in range(len(os.listdir(main_path))):\n",
    "    im = cv2.imread(main_path+'/'+np.sort(os.listdir(main_path))[i])\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = resize(im, (img_dims, img_dims, 3))\n",
    "    im = np.reshape(im, (1, 256, 256,3))\n",
    "    if np.max(np.unique(im))>1.0:\n",
    "      im = im/255.0\n",
    "\n",
    "    p = (model.predict(im[0:1]))[0]\n",
    "    p_rounded = (p==p[np.argmax(p)])*1.0\n",
    "    tot+=1\n",
    "    if class_type=='binary':\n",
    "       conf_array[k,int(p_rounded[0])]+=1\n",
    "       if not (i%10): print('class: ', k, ' name: ', files_list[k],'; img ', i, ' of ' ,len(os.listdir(main_path)),'; prediction =', p)\n",
    "    else:\n",
    "      conf_array[k,np.argmax(p_rounded)]+=1\n",
    "      if not (i%10): print('class: ', k, ' name: ', files_list[k],'; img ', i, ' of ' ,len(os.listdir(main_path)),'; prediction =', p_rounded, ' (',tot,')' )\n",
    "    \n",
    "    # plt.imshow(im[0])\n",
    "    # if i>20: break\n",
    "  # break\n",
    "print('********************')\n",
    "# conf_array\n",
    "\n",
    "print(files_list)\n",
    "print('\\n')\n",
    "conf_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro Precision=Recall=F1=Acc\n",
    "\n",
    "\n",
    "Relavant sites for implementing micro, macro and weighted quantities\n",
    "\n",
    " https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1\n",
    " \n",
    " https://androidkt.com/micro-macro-averages-for-imbalance-multiclass-classification/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "f = 0 \n",
    "\n",
    "\n",
    "for i in range(conf_array.shape[0]):\n",
    "  for j in range(conf_array.shape[1]):\n",
    "      if i==j:  \n",
    "        tp = tp +conf_array[i,j] \n",
    "\n",
    "print('Micro Avg & Accuracy:', tp/(np.sum(conf_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = []\n",
    "fn = [] \n",
    "fp = []\n",
    "\n",
    "precs = []\n",
    "recs = []\n",
    "\n",
    "for i in range(conf_array.shape[0]):\n",
    "  for j in range(conf_array.shape[1]):\n",
    "      if i==j:  \n",
    "        tp.append(conf_array[i,j])\n",
    "      else:\n",
    "        fn.append(conf_array[i,j]) \n",
    "        fp.append(conf_array[j,i]) \n",
    "  recs.append(np.sum(tp)/(np.sum(tp)+np.sum(fn)))\n",
    "  precs.append(np.sum(tp)/(np.sum(tp)+np.sum(fp)))\n",
    "\n",
    "  # print(tp, fn, fp)\n",
    "  # print(recs , precs, '__')\n",
    "  tp=[]\n",
    "  fn=[]\n",
    "  fp=[]\n",
    "  \n",
    "PREC = np.mean(precs)\n",
    "REC = np.mean(recs)\n",
    "\n",
    "print(\"Macro Precision:\", PREC)\n",
    "print(\"Macro Recall:\", REC)\n",
    "print(\"Macro F1-Score:\", 2*PREC*REC/(PREC+REC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.sum(conf_array,axis=1)\n",
    "\n",
    "weighted_PREC = np.sum([precs[i]*label_counts[i] for i in range(len(precs))])/np.sum(label_counts)\n",
    "weighted_REC = np.sum([recs[i]*label_counts[i] for i in range(len(recs))])/np.sum(label_counts)\n",
    "\n",
    "print(\"Weighted Precision:\", weighted_PREC)\n",
    "print(\"Weighted Recall:\", weighted_REC)\n",
    "print(\"Weighted F1-Score:\", 2*weighted_PREC*weighted_REC/(weighted_PREC+weighted_REC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1d9cc4cb1d0fcc14a2649d1e6b04863f2bc6b3f1f495de899c81d07a02e7cb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
